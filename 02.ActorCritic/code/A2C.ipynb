{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gym\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    \n",
    "    def __init__(self, obs_dim, act_dim, hidden_size = 64):\n",
    "        '''\n",
    "        Initializing a 2 layer neural net\n",
    "        '''\n",
    "        super(Actor, self).__init__()\n",
    "        self.policy = nn.Sequential(\n",
    "                        nn.Linear(obs_dim, hidden_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(hidden_size, act_dim),\n",
    "                        nn.Softmax(dim = -1)\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input:\n",
    "            -x : A tensor of shape [batch_size, obs_dim] representing the state\n",
    "        \n",
    "        Returns a tensor of shape [batch_size, act_dim] representing the probability of taking each action\n",
    "        '''\n",
    "        return self.policy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    \n",
    "    def __init__(self, obs_dim, hidden_size = 64):\n",
    "        '''\n",
    "        Initializing a 2 layer neural net\n",
    "        '''\n",
    "        super(Critic, self).__init__()\n",
    "        self.value = nn.Sequential(\n",
    "                        nn.Linear(obs_dim, hidden_size),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(hidden_size, 1),\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input:\n",
    "            -x : A tensor of shape [batch_size, obs_dim] representing the state\n",
    "        \n",
    "        Returns a tensor of shape [batch_size, 1] representing the value function of input state\n",
    "        '''\n",
    "        return self.value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_act = Actor(obs_dim, act_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_crt = Critic(obs_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(\n",
       "  (policy): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
       "    (3): Softmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (value): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_crt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_act = optim.Adam(net_act.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_crt = optim.Adam(net_crt.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_q_vals(rewards, last_q_val, gamma):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Computes the q values using the finite horizon method as we saw in the slides\n",
    "    \n",
    "    Inputs:\n",
    "        - rewards : A tensor containing rewards for T time steps\n",
    "        - last_val : Value function of the last state\n",
    "        - gamma : discount factor\n",
    "    '''\n",
    "    \n",
    "    q_vals = torch.zeros_like(rewards)\n",
    "    q_vals[-1] = last_val.squeeze()\n",
    "    \n",
    "    for t in reversed(range(len(rewards)-1)):\n",
    "        q_vals[t] = rewards[t] + gamma * q_vals[t+1]\n",
    "        \n",
    "    return q_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def an_actors_life(env, net_act, net_crt, init_state, gamma =0.99, T = 20):\n",
    "    \n",
    "    '''\n",
    "    Actor interacts with environment for T steps, then computes the policy and value gradients and store them\n",
    "    \n",
    "    Inputs:\n",
    "        - env : Gym environment\n",
    "        - net_act : Actor network\n",
    "        - net_crt : Critic network\n",
    "        - init_state : Initial state to start the trajectory from\n",
    "        - gamma : discount factor\n",
    "        - T : Horizon length\n",
    "    '''\n",
    "    \n",
    "    states = []\n",
    "    logps = []\n",
    "    rewards = []\n",
    "    state = init_state\n",
    "    \n",
    "    #Play the game for T steps\n",
    "    for i in range(T):\n",
    "        states.append(state)\n",
    "        state_v = torch.FloatTensor([state])\n",
    "        p_v = net_act(state_v)\n",
    "        p = p_v.detach().numpy().squeeze()\n",
    "        action = np.random.choice(np.arange(act_dim), p = p)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        logps.append(torch.log(p_v)[:1, action])\n",
    "        \n",
    "        if done:\n",
    "            state = env.reset()\n",
    "            break\n",
    "    \n",
    "    #Converting states, logps and rewards to torch tensors\n",
    "    states_v = torch.FloatTensor(states)\n",
    "    logps_v = torch.cat(logps, dim = 0)\n",
    "    rewards_v = torch.FloatTensor(rewards)\n",
    "    \n",
    "    #Defining the value function corresponding to the final state\n",
    "    if done:\n",
    "        last_val = torch.FloatTensor([0])\n",
    "    else:\n",
    "        last_val = net_crt(states_v[-1:])\n",
    "    \n",
    "    #Compute advantages\n",
    "    q_vals = find_q_vals(rewards_v, last_val, gamma).detach()\n",
    "    vals = net_crt(states_v)\n",
    "    advs = (q_vals - vals.squeeze()).detach()\n",
    "    \n",
    "    #Accumulate the gradients for critic\n",
    "    loss_crt = ((q_vals - vals.squeeze())**2).mean()\n",
    "    loss_crt.backward()\n",
    "    \n",
    "    #Accumulate the gradients of actor\n",
    "    loss_act = (-logps_v * advs).mean()\n",
    "    loss_act.backward()\n",
    "    \n",
    "    return env, state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env, net_act):\n",
    "    \n",
    "    state = env.reset()\n",
    "    tot_reward = 0\n",
    "    while True:\n",
    "        state_v = torch.FloatTensor(state).unsqueeze(0)\n",
    "        p_v = net_act(state_v)\n",
    "        p = p_v.detach().numpy().squeeze()\n",
    "        action = np.random.choice(np.arange(act_dim), p = p)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "\n",
    "        tot_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    return tot_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A2C(env, net_act, net_crt, opti_act, opti_crt, N_actrs = 10, T = 20, num_runs = 20000, gamma = 0.99, test_every = 1):\n",
    "    \n",
    "    \n",
    "    running_return = 0\n",
    "    running_returns = []\n",
    "    ep = 0\n",
    "    t = 0\n",
    "    state = env.reset()\n",
    "    states = []\n",
    "    logps = []\n",
    "    rewards = []\n",
    "    \n",
    "    #Allocate different environment for each actor\n",
    "    envs = [copy.deepcopy(env) for _ in range(N_actrs)]\n",
    "    states = [env.reset() for env in envs]\n",
    "    for i in range(num_runs):\n",
    "        \n",
    "        net_act.zero_grad()\n",
    "        net_crt.zero_grad()\n",
    "        \n",
    "        #All actors play their parts\n",
    "        for n in range(N_actrs):\n",
    "            env, state = an_actors_life(envs[n], net_act, net_crt, states[n])\n",
    "            envs[n] = env\n",
    "            states[n] = state\n",
    "            \n",
    "        #Update actor and critic    \n",
    "        opti_crt.step()\n",
    "        opti_act.step()\n",
    "        \n",
    "        if (i+1)%test_every == 0:\n",
    "            tot_rewards = test(env, net_act)\n",
    "            running_return = 0.1*tot_rewards + 0.9*running_return\n",
    "            running_returns.append(running_return)\n",
    "            \n",
    "            print(\"Iteration {} Total reward {}, mean return {}\".format(i+1, tot_rewards, np.round(running_return,2)))\n",
    "            \n",
    "    return running_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 Total reward 37.0, mean return 3.7\n",
      "Iteration 2 Total reward 30.0, mean return 6.33\n",
      "Iteration 3 Total reward 23.0, mean return 8.0\n",
      "Iteration 4 Total reward 47.0, mean return 11.9\n",
      "Iteration 5 Total reward 34.0, mean return 14.11\n",
      "Iteration 6 Total reward 33.0, mean return 16.0\n",
      "Iteration 7 Total reward 31.0, mean return 17.5\n",
      "Iteration 8 Total reward 16.0, mean return 17.35\n",
      "Iteration 9 Total reward 77.0, mean return 23.31\n",
      "Iteration 10 Total reward 31.0, mean return 24.08\n",
      "Iteration 11 Total reward 35.0, mean return 25.17\n",
      "Iteration 12 Total reward 41.0, mean return 26.76\n",
      "Iteration 13 Total reward 40.0, mean return 28.08\n",
      "Iteration 14 Total reward 62.0, mean return 31.47\n",
      "Iteration 15 Total reward 105.0, mean return 38.83\n",
      "Iteration 16 Total reward 71.0, mean return 42.04\n",
      "Iteration 17 Total reward 88.0, mean return 46.64\n",
      "Iteration 18 Total reward 67.0, mean return 48.67\n",
      "Iteration 19 Total reward 79.0, mean return 51.71\n",
      "Iteration 20 Total reward 61.0, mean return 52.64\n",
      "Iteration 21 Total reward 68.0, mean return 54.17\n",
      "Iteration 22 Total reward 40.0, mean return 52.76\n",
      "Iteration 23 Total reward 60.0, mean return 53.48\n",
      "Iteration 24 Total reward 96.0, mean return 57.73\n",
      "Iteration 25 Total reward 43.0, mean return 56.26\n",
      "Iteration 26 Total reward 42.0, mean return 54.83\n",
      "Iteration 27 Total reward 105.0, mean return 59.85\n",
      "Iteration 28 Total reward 54.0, mean return 59.26\n",
      "Iteration 29 Total reward 23.0, mean return 55.64\n",
      "Iteration 30 Total reward 35.0, mean return 53.57\n",
      "Iteration 31 Total reward 25.0, mean return 50.72\n",
      "Iteration 32 Total reward 40.0, mean return 49.65\n",
      "Iteration 33 Total reward 99.0, mean return 54.58\n",
      "Iteration 34 Total reward 67.0, mean return 55.82\n",
      "Iteration 35 Total reward 196.0, mean return 69.84\n",
      "Iteration 36 Total reward 155.0, mean return 78.36\n",
      "Iteration 37 Total reward 73.0, mean return 77.82\n",
      "Iteration 38 Total reward 196.0, mean return 89.64\n",
      "Iteration 39 Total reward 200.0, mean return 100.67\n",
      "Iteration 40 Total reward 197.0, mean return 110.31\n",
      "Iteration 41 Total reward 120.0, mean return 111.28\n",
      "Iteration 42 Total reward 165.0, mean return 116.65\n",
      "Iteration 43 Total reward 200.0, mean return 124.98\n",
      "Iteration 44 Total reward 134.0, mean return 125.89\n",
      "Iteration 45 Total reward 111.0, mean return 124.4\n",
      "Iteration 46 Total reward 121.0, mean return 124.06\n",
      "Iteration 47 Total reward 181.0, mean return 129.75\n",
      "Iteration 48 Total reward 132.0, mean return 129.98\n",
      "Iteration 49 Total reward 141.0, mean return 131.08\n",
      "Iteration 50 Total reward 195.0, mean return 137.47\n",
      "Iteration 51 Total reward 136.0, mean return 137.32\n",
      "Iteration 52 Total reward 200.0, mean return 143.59\n",
      "Iteration 53 Total reward 42.0, mean return 133.43\n",
      "Iteration 54 Total reward 62.0, mean return 126.29\n",
      "Iteration 55 Total reward 140.0, mean return 127.66\n",
      "Iteration 56 Total reward 146.0, mean return 129.49\n",
      "Iteration 57 Total reward 200.0, mean return 136.54\n",
      "Iteration 58 Total reward 200.0, mean return 142.89\n",
      "Iteration 59 Total reward 200.0, mean return 148.6\n",
      "Iteration 60 Total reward 188.0, mean return 152.54\n",
      "Iteration 61 Total reward 200.0, mean return 157.29\n",
      "Iteration 62 Total reward 200.0, mean return 161.56\n",
      "Iteration 63 Total reward 200.0, mean return 165.4\n",
      "Iteration 64 Total reward 172.0, mean return 166.06\n",
      "Iteration 65 Total reward 165.0, mean return 165.96\n",
      "Iteration 66 Total reward 200.0, mean return 169.36\n",
      "Iteration 67 Total reward 115.0, mean return 163.92\n",
      "Iteration 68 Total reward 137.0, mean return 161.23\n",
      "Iteration 69 Total reward 148.0, mean return 159.91\n",
      "Iteration 70 Total reward 143.0, mean return 158.22\n",
      "Iteration 71 Total reward 45.0, mean return 146.9\n",
      "Iteration 72 Total reward 153.0, mean return 147.51\n",
      "Iteration 73 Total reward 200.0, mean return 152.76\n",
      "Iteration 74 Total reward 168.0, mean return 154.28\n",
      "Iteration 75 Total reward 200.0, mean return 158.85\n",
      "Iteration 76 Total reward 166.0, mean return 159.57\n",
      "Iteration 77 Total reward 200.0, mean return 163.61\n",
      "Iteration 78 Total reward 200.0, mean return 167.25\n",
      "Iteration 79 Total reward 200.0, mean return 170.52\n",
      "Iteration 80 Total reward 199.0, mean return 173.37\n",
      "Iteration 81 Total reward 166.0, mean return 172.63\n",
      "Iteration 82 Total reward 200.0, mean return 175.37\n",
      "Iteration 83 Total reward 200.0, mean return 177.83\n",
      "Iteration 84 Total reward 200.0, mean return 180.05\n",
      "Iteration 85 Total reward 200.0, mean return 182.05\n",
      "Iteration 86 Total reward 200.0, mean return 183.84\n",
      "Iteration 87 Total reward 200.0, mean return 185.46\n",
      "Iteration 88 Total reward 200.0, mean return 186.91\n",
      "Iteration 89 Total reward 200.0, mean return 188.22\n",
      "Iteration 90 Total reward 155.0, mean return 184.9\n",
      "Iteration 91 Total reward 200.0, mean return 186.41\n",
      "Iteration 92 Total reward 200.0, mean return 187.77\n",
      "Iteration 93 Total reward 200.0, mean return 188.99\n",
      "Iteration 94 Total reward 185.0, mean return 188.59\n",
      "Iteration 95 Total reward 135.0, mean return 183.23\n",
      "Iteration 96 Total reward 192.0, mean return 184.11\n",
      "Iteration 97 Total reward 200.0, mean return 185.7\n",
      "Iteration 98 Total reward 200.0, mean return 187.13\n",
      "Iteration 99 Total reward 117.0, mean return 180.12\n",
      "Iteration 100 Total reward 111.0, mean return 173.2\n",
      "Iteration 101 Total reward 116.0, mean return 167.48\n",
      "Iteration 102 Total reward 108.0, mean return 161.54\n",
      "Iteration 103 Total reward 110.0, mean return 156.38\n",
      "Iteration 104 Total reward 49.0, mean return 145.64\n",
      "Iteration 105 Total reward 136.0, mean return 144.68\n",
      "Iteration 106 Total reward 107.0, mean return 140.91\n",
      "Iteration 107 Total reward 137.0, mean return 140.52\n",
      "Iteration 108 Total reward 112.0, mean return 137.67\n",
      "Iteration 109 Total reward 104.0, mean return 134.3\n",
      "Iteration 110 Total reward 113.0, mean return 132.17\n",
      "Iteration 111 Total reward 100.0, mean return 128.95\n",
      "Iteration 112 Total reward 125.0, mean return 128.56\n",
      "Iteration 113 Total reward 200.0, mean return 135.7\n",
      "Iteration 114 Total reward 200.0, mean return 142.13\n",
      "Iteration 115 Total reward 200.0, mean return 147.92\n",
      "Iteration 116 Total reward 117.0, mean return 144.83\n",
      "Iteration 117 Total reward 121.0, mean return 142.44\n",
      "Iteration 118 Total reward 113.0, mean return 139.5\n",
      "Iteration 119 Total reward 97.0, mean return 135.25\n",
      "Iteration 120 Total reward 119.0, mean return 133.63\n",
      "Iteration 121 Total reward 100.0, mean return 130.26\n",
      "Iteration 122 Total reward 110.0, mean return 128.24\n",
      "Iteration 123 Total reward 107.0, mean return 126.11\n",
      "Iteration 124 Total reward 120.0, mean return 125.5\n",
      "Iteration 125 Total reward 102.0, mean return 123.15\n",
      "Iteration 126 Total reward 109.0, mean return 121.74\n",
      "Iteration 127 Total reward 109.0, mean return 120.46\n",
      "Iteration 128 Total reward 110.0, mean return 119.42\n",
      "Iteration 129 Total reward 56.0, mean return 113.07\n",
      "Iteration 130 Total reward 120.0, mean return 113.77\n",
      "Iteration 131 Total reward 106.0, mean return 112.99\n",
      "Iteration 132 Total reward 117.0, mean return 113.39\n",
      "Iteration 133 Total reward 126.0, mean return 114.65\n",
      "Iteration 134 Total reward 119.0, mean return 115.09\n",
      "Iteration 135 Total reward 114.0, mean return 114.98\n",
      "Iteration 136 Total reward 120.0, mean return 115.48\n",
      "Iteration 137 Total reward 120.0, mean return 115.93\n",
      "Iteration 138 Total reward 138.0, mean return 118.14\n",
      "Iteration 139 Total reward 112.0, mean return 117.53\n",
      "Iteration 140 Total reward 103.0, mean return 116.07\n",
      "Iteration 141 Total reward 153.0, mean return 119.77\n",
      "Iteration 142 Total reward 121.0, mean return 119.89\n",
      "Iteration 143 Total reward 114.0, mean return 119.3\n",
      "Iteration 144 Total reward 112.0, mean return 118.57\n",
      "Iteration 145 Total reward 111.0, mean return 117.81\n",
      "Iteration 146 Total reward 118.0, mean return 117.83\n",
      "Iteration 147 Total reward 125.0, mean return 118.55\n",
      "Iteration 148 Total reward 123.0, mean return 118.99\n",
      "Iteration 149 Total reward 137.0, mean return 120.79\n",
      "Iteration 150 Total reward 140.0, mean return 122.71\n",
      "Iteration 151 Total reward 173.0, mean return 127.74\n",
      "Iteration 152 Total reward 152.0, mean return 130.17\n",
      "Iteration 153 Total reward 200.0, mean return 137.15\n",
      "Iteration 154 Total reward 200.0, mean return 143.44\n",
      "Iteration 155 Total reward 200.0, mean return 149.09\n",
      "Iteration 156 Total reward 200.0, mean return 154.18\n",
      "Iteration 157 Total reward 200.0, mean return 158.77\n",
      "Iteration 158 Total reward 200.0, mean return 162.89\n",
      "Iteration 159 Total reward 200.0, mean return 166.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 160 Total reward 200.0, mean return 169.94\n",
      "Iteration 161 Total reward 200.0, mean return 172.95\n",
      "Iteration 162 Total reward 200.0, mean return 175.65\n",
      "Iteration 163 Total reward 200.0, mean return 178.09\n",
      "Iteration 164 Total reward 200.0, mean return 180.28\n",
      "Iteration 165 Total reward 200.0, mean return 182.25\n",
      "Iteration 166 Total reward 200.0, mean return 184.02\n",
      "Iteration 167 Total reward 138.0, mean return 179.42\n",
      "Iteration 168 Total reward 200.0, mean return 181.48\n",
      "Iteration 169 Total reward 169.0, mean return 180.23\n",
      "Iteration 170 Total reward 146.0, mean return 176.81\n",
      "Iteration 171 Total reward 200.0, mean return 179.13\n",
      "Iteration 172 Total reward 200.0, mean return 181.22\n",
      "Iteration 173 Total reward 200.0, mean return 183.09\n",
      "Iteration 174 Total reward 200.0, mean return 184.78\n",
      "Iteration 175 Total reward 200.0, mean return 186.31\n",
      "Iteration 176 Total reward 200.0, mean return 187.68\n",
      "Iteration 177 Total reward 200.0, mean return 188.91\n",
      "Iteration 178 Total reward 200.0, mean return 190.02\n",
      "Iteration 179 Total reward 200.0, mean return 191.02\n",
      "Iteration 180 Total reward 200.0, mean return 191.91\n",
      "Iteration 181 Total reward 200.0, mean return 192.72\n",
      "Iteration 182 Total reward 200.0, mean return 193.45\n",
      "Iteration 183 Total reward 200.0, mean return 194.11\n",
      "Iteration 184 Total reward 200.0, mean return 194.69\n",
      "Iteration 185 Total reward 200.0, mean return 195.23\n",
      "Iteration 186 Total reward 200.0, mean return 195.7\n",
      "Iteration 187 Total reward 200.0, mean return 196.13\n",
      "Iteration 188 Total reward 200.0, mean return 196.52\n",
      "Iteration 189 Total reward 200.0, mean return 196.87\n",
      "Iteration 190 Total reward 200.0, mean return 197.18\n",
      "Iteration 191 Total reward 200.0, mean return 197.46\n",
      "Iteration 192 Total reward 200.0, mean return 197.72\n",
      "Iteration 193 Total reward 200.0, mean return 197.94\n",
      "Iteration 194 Total reward 200.0, mean return 198.15\n",
      "Iteration 195 Total reward 200.0, mean return 198.34\n",
      "Iteration 196 Total reward 200.0, mean return 198.5\n",
      "Iteration 197 Total reward 200.0, mean return 198.65\n",
      "Iteration 198 Total reward 200.0, mean return 198.79\n",
      "Iteration 199 Total reward 200.0, mean return 198.91\n",
      "Iteration 200 Total reward 200.0, mean return 199.02\n"
     ]
    }
   ],
   "source": [
    "running_returns = A2C(env, net_act, net_crt, opti_act, opti_crt, num_runs = 200, N_actrs = 20, T = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Training iterations')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(running_returns)\n",
    "plt.xlabel(\"Mean returns\")\n",
    "plt.ylabel(\"Training iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net_act.state_dict(),'Policies/cart_pole.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    state = env.reset()\n",
    "    tot_reward = 0\n",
    "    while True:\n",
    "        env.render()\n",
    "        time.sleep(.03)\n",
    "        state_v = torch.FloatTensor(state).unsqueeze(0)\n",
    "        p_v = net_act(state_v)\n",
    "        p = p_v.detach().numpy().squeeze()\n",
    "        action = np.argmax(p)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        tot_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "print(tot_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
